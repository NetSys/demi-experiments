{
  "additional_metadata": null,
  "argv": [
    "./../../../../.././interposition/src/main/python/setup.py",
    "-t",
    "-n",
    "spark-fuzz"
  ],
  "cwd": "/Users/cs/Research/UCB/code/sts2-applications",
  "host": {
    "cpu_info": "",
    "free": "",
    "name": "yossarian",
    "num_cores": "0",
    "uptime": "17:53  up 4 days, 20:44, 8 users, load averages: 2.22 1.96 1.90"
  },
  "modules": {
    "sts2": {
      "branch": "spark-2294-blocks",
      "commit": "513c2048a0707d98dd617120aa4f2ef338dbd371",
      "diff": "diff --git a/interposition/src/main/scala/verification/Instrumenter.scala b/interposition/src/main/scala/verification/Instrumenter.scala\nindex e3c31ab..99e2a85 100644\n--- a/interposition/src/main/scala/verification/Instrumenter.scala\n+++ b/interposition/src/main/scala/verification/Instrumenter.scala\n@@ -356,9 +356,7 @@ class Instrumenter {\n   // block until Instrumenter.beginAtomicBlock is invoked.\n   var messagesToBlockAfterToTaskId = new HashMap[Any, Long]\n   def blockForAtomicAfterNextMessage(taskId: Long, message: Any) {\n-    if ((!Instrumenter.threadNameIsAkkaInternal) ||\n-        sendingKnownExternalMessages.get) {\n-      // External thread (or ScheduleBlock), so we don't care if it blocks.\n+    if (Instrumenter.threadNameIsAkkaInternal) {\n       return\n     }\n     logger.trace(s\"Instrumenter.blockForAtomicAfterNextMessage $taskId $message\")\n@@ -814,6 +812,7 @@ class Instrumenter {\n \n   // Return whether to allow the answer through or not\n   def receiveAskAnswer(temp: PromiseActorRef, msg: Any, sender: ActorRef) : Boolean = {\n+    println(\"receiveAskAnswer\")\n     if (_passThrough.get()) {\n       return true\n     }\n@@ -824,6 +823,7 @@ class Instrumenter {\n \n     if (!(tempToParent contains temp.path)) {\n       // temp actor was spawned by an external thread\n+      println(\"!(tempToParent contains temp.path)\")\n       return true\n     }\n     // Assume it's impossible for an internal actor to `ask` the outside world\n@@ -1059,11 +1059,10 @@ class Instrumenter {\n     // If so, do a bit of bookkeeping.\n     // TODO(cs): assume that temp actors aren't used for anything other than\n     // ask. Which probably isn't a good assumption.\n-    if (envelope.sender.path.parent.name == \"temp\" && currentActor != \"\") {\n+    if (envelope.sender.path.parent.name == \"temp\" && currentActor != \"\" && Instrumenter.threadNameIsAkkaInternal) {\n       tempToParent(envelope.sender.path) = currentActor\n     }\n \n-\n     // If this is not a system message then check if we have already recorded\n     // this event. Recorded => we are injecting this event (as opposed to some\n     // actor doing it in which case we need to report it)\ndiff --git a/interposition/src/main/scala/verification/RunnerUtils.scala b/interposition/src/main/scala/verification/RunnerUtils.scala\nindex 7110772..9eb5913 100644\n--- a/interposition/src/main/scala/verification/RunnerUtils.scala\n+++ b/interposition/src/main/scala/verification/RunnerUtils.scala\n@@ -130,6 +130,7 @@ object RunnerUtils {\n                   shouldRerunDDMin:(Seq[ExternalEvent] => Boolean)=(_)=>true,\n                   initializationRoutine: Option[() => Any]=None,\n                   clusteringStrategy:ClusteringStrategy.ClusteringStrategy=ClusteringStrategy.ClockClusterizer,\n+                  fungClocksScheduler:TestScheduler.TestScheduler=TestScheduler.DPORwHeuristics, // Hack: remove after we have Spark support for DPOR\n                   preTest: Option[STSScheduler.PreTestCallback]=None,\n                   postTest: Option[STSScheduler.PostTestCallback]=None) {\n \n@@ -329,7 +330,7 @@ object RunnerUtils {\n           new FungibleClockMinimizer(schedulerConfig,\n             currentExternals,\n             currentTrace, actors, violationFound,\n-            //testScheduler=TestScheduler.DPORwHeuristics,\n+            //testScheduler=fungClocksScheduler,\n             stats=Some(currentStats),\n             clusteringStrategy=clusteringStrategy,\n             initializationRoutine=initializationRoutine,\n@@ -356,7 +357,7 @@ object RunnerUtils {\n         def minimize(currentExternals: Seq[ExternalEvent], currentTrace: EventTrace, currentStats: MinimizationStats) =\n           new FungibleClockMinimizer(schedulerConfig, currentExternals,\n             currentTrace, actors, violationFound,\n-            testScheduler=TestScheduler.DPORwHeuristics,\n+            testScheduler=fungClocksScheduler,\n             timeBudgetSeconds=timeBudgetSeconds,\n             clusteringStrategy=clusteringStrategy,\n             stats=Some(currentStats),\n@@ -380,7 +381,7 @@ object RunnerUtils {\n               }.toSeq),\n               violationFound,\n               actors,\n-              testScheduler=TestScheduler.DPORwHeuristics,\n+              testScheduler=fungClocksScheduler,\n               timeBudgetSeconds=timeBudgetSeconds,\n               stats=Some(currentStats),\n               initializationRoutine=initializationRoutine,\n@@ -604,6 +605,7 @@ object RunnerUtils {\n       }\n       return (mcs.events, ddmin._stats, validated_mcs, violation)\n     } else {\n+      // TODO(cs): return the smallest trace DDMin was able to trigger so far?\n       return (mcs.events, ddmin._stats, Some(trace), violation)\n     }\n   }\ndiff --git a/interposition/src/main/scala/verification/minification/domain_specific/FungibleClockClustering.scala b/interposition/src/main/scala/verification/minification/domain_specific/FungibleClockClustering.scala\nindex abce347..e3c1426 100644\n--- a/interposition/src/main/scala/verification/minification/domain_specific/FungibleClockClustering.scala\n+++ b/interposition/src/main/scala/verification/minification/domain_specific/FungibleClockClustering.scala\n@@ -217,6 +217,7 @@ class FungibleClockMinimizer(\n \n   def testWithSTSSched(nextTrace: EventTrace, stats: MinimizationStats,\n                        absentIgnored: STSScheduler.IgnoreAbsentCallback): Option[EventTrace] = {\n+    println(\"testWithSTSSched!\")\n     return RunnerUtils.testWithStsSched(\n       schedulerConfig,\n       mcs,\n@@ -266,6 +267,7 @@ class FungibleClockMinimizer(\n     var minTrace = trace\n \n     var nextTrace = clusterizer.getNextTrace(false, Set[Int]())\n+    println(\"clusterizer.getNextTrace: \" + nextTrace.size)\n     // don't overwrite prune start if we're being used as a TestOracle\n     if (!skipClockClusters) _stats.record_prune_start\n     while (!nextTrace.isEmpty) {\n@@ -310,6 +312,7 @@ class FungibleClockMinimizer(\n         }\n       }\n       nextTrace = clusterizer.getNextTrace(!ret.isEmpty, ignoredAbsentIds)\n+      println(\"clusterizer.getNextTrace: \" + nextTrace.size)\n     }\n \n     // don't overwrite prune end if we're being used as a TestOracle\ndiff --git a/interposition/src/main/scala/verification/minification/domain_specific/OneAtATimeClusterizer.scala b/interposition/src/main/scala/verification/minification/domain_specific/OneAtATimeClusterizer.scala\nindex 606f759..e919b6b 100644\n--- a/interposition/src/main/scala/verification/minification/domain_specific/OneAtATimeClusterizer.scala\n+++ b/interposition/src/main/scala/verification/minification/domain_specific/OneAtATimeClusterizer.scala\n@@ -17,14 +17,15 @@ class SingletonClusterizer(\n \n   val log = LoggerFactory.getLogger(\"SingletonClusterizer\")\n \n-  var sortedIds = getIdsToRemove\n-  val allIds = sortedIds.toSet\n+  var sortedIds = getIdsToRemove()\n+  val allIds = sortedIds.toSet | getUnignorableIds()\n   var successfullyRemoved = Set[Int]()\n   var ignoredLastRun = -1\n+  var firstRun = true\n \n   def getIdsToRemove(): Seq[Int] = {\n     var inUnignorableBlock = false\n-    originalTrace.flatMap {\n+    originalTrace.events.flatMap {\n       case BeginUnignorableEvents =>\n         inUnignorableBlock = true\n         None\n@@ -40,6 +41,24 @@ class SingletonClusterizer(\n     }.toSeq.sorted // Should already be sorted?\n   }\n \n+  def getUnignorableIds(): Set[Int] = {\n+    var inUnignorableBlock = false\n+    originalTrace.events.flatMap {\n+      case BeginUnignorableEvents =>\n+        inUnignorableBlock = true\n+        None\n+      case EndUnignorableEvents =>\n+        inUnignorableBlock = false\n+        None\n+      case UniqueMsgEvent(m, id)\n+        if (EventTypes.isExternal(m) || inUnignorableBlock) =>\n+        Some(id)\n+      case t @ UniqueTimerDelivery(_, _) =>\n+        throw new IllegalArgumentException(\"TimerDelivery not supported. Replay first\")\n+      case e => None\n+    }.toSet\n+  }\n+\n   // Iteration:\n   // - Pick an event to remove\n   // - Wildcard all subsequent events\n@@ -58,8 +77,13 @@ class SingletonClusterizer(\n       successfullyRemoved = (successfullyRemoved | ignoredAbsentIds) + ignoredLastRun\n     }\n \n-    ignoredLastRun = sortedIds.head\n-    sortedIds = sortedIds.tail\n+    if (!firstRun) {\n+      ignoredLastRun = sortedIds.head\n+      log.info(s\"Trying to ignore $ignoredLastRun\")\n+      sortedIds = sortedIds.tail\n+    } else {\n+      firstRun = false\n+    }\n \n     val currentCluster = allIds -- (successfullyRemoved - ignoredLastRun)\n \n@@ -70,6 +94,7 @@ class SingletonClusterizer(\n         Some(u)\n       case UniqueMsgEvent(MsgEvent(snd,rcv,msg), id) =>\n         if (currentCluster contains id) {\n+          assert(!msg.isInstanceOf[MessageFingerprint])\n           val classTag = ClassTag(msg.getClass)\n           def messageFilter(pendingMsg: Any): Boolean = {\n             ClassTag(pendingMsg.getClass) == classTag\ndiff --git a/src/main/scala/spark/core/src/main/scala/org/apache/spark/storage/BlockManager.scala b/src/main/scala/spark/core/src/main/scala/org/apache/spark/storage/BlockManager.scala\nindex 10ec983..82bf9cd 100644\n--- a/src/main/scala/spark/core/src/main/scala/org/apache/spark/storage/BlockManager.scala\n+++ b/src/main/scala/spark/core/src/main/scala/org/apache/spark/storage/BlockManager.scala\n@@ -36,6 +36,8 @@ import org.apache.spark.network._\n import org.apache.spark.serializer.Serializer\n import org.apache.spark.util._\n \n+import akka.dispatch.verification.Util\n+\n private[spark] sealed trait BlockValues\n private[spark] case class ByteBufferValues(buffer: ByteBuffer) extends BlockValues\n private[spark] case class IteratorValues(iterator: Iterator[Any]) extends BlockValues\n@@ -303,7 +305,9 @@ private[spark] class BlockManager(\n    * and the updated in-memory and on-disk sizes.\n    */\n   private def getCurrentBlockStatus(blockId: BlockId, info: BlockInfo): BlockStatus = {\n-    info.synchronized {\n+    val stackTrace = Util.getStackTrace(new RuntimeException(\"doGetLocal\"))\n+    println(s\"Synchronizing on $info getCurrentBlockStatus ${Thread.currentThread.getName} $stackTrace\")\n+    val ret = info.synchronized {\n       info.level match {\n         case null =>\n           BlockStatus(StorageLevel.NONE, 0L, 0L, 0L)\n@@ -320,6 +324,8 @@ private[spark] class BlockManager(\n           BlockStatus(storageLevel, memSize, diskSize, tachyonSize)\n       }\n     }\n+    println(s\"Done synchronizing on $info getCurrentBlockStatus ${Thread.currentThread.getName} $stackTrace\")\n+    ret\n   }\n \n   /**\n@@ -374,7 +380,10 @@ private[spark] class BlockManager(\n   private def doGetLocal(blockId: BlockId, asBlockResult: Boolean): Option[Any] = {\n     val info = blockInfo.get(blockId).orNull\n     if (info != null) {\n+      val stackTrace = Util.getStackTrace(new RuntimeException(\"doGetLocal\"))\n+      println(s\"doGetLocal Synchronizing on $info ${Thread.currentThread.getName} $stackTrace\")\n       info.synchronized {\n+        println(\"doGetLocal got the lock \" + info)\n         // Double check to make sure the block is still there. There is a small chance that the\n         // block has been removed by removeBlock (which also synchronizes on the blockInfo object).\n         // Note that this only checks metadata tracking. If user intentionally deleted the block\n@@ -386,12 +395,15 @@ private[spark] class BlockManager(\n         }\n \n         // If another thread is writing the block, wait for it to become ready.\n+        println(\"waitForReady()\")\n         if (!info.waitForReady()) {\n           // If we get here, the block write failed.\n           logWarning(s\"Block $blockId was marked as failure.\")\n           return None\n         }\n \n+        println(\"done waitForReady()\")\n+\n         val level = info.level\n         logDebug(s\"Level for block $blockId is $level\")\n \n@@ -669,6 +681,7 @@ private[spark] class BlockManager(\n       case _ => null\n     }\n \n+    println(s\"doPut Synchronizing on $putBlockInfo ${Thread.currentThread.getName}\")\n     putBlockInfo.synchronized {\n       logTrace(\"Put for block %s took %s to get into synchronized block\"\n         .format(blockId, Utils.getUsedTimeMs(startTimeMs)))\n@@ -839,6 +852,7 @@ private[spark] class BlockManager(\n \n     // If the block has not already been dropped\n     if (info != null) {\n+      println(s\"dropFromMemory Synchronizing on $info ${Thread.currentThread.getName}\")\n       info.synchronized {\n         // required ? As of now, this will be invoked only for blocks which are ready\n         // But in case this changes in future, adding for consistency sake.\n@@ -920,6 +934,7 @@ private[spark] class BlockManager(\n     logInfo(s\"Removing block $blockId\")\n     val info = blockInfo.get(blockId).orNull\n     if (info != null) {\n+      println(s\"removeBlock Synchronizing on $info ${Thread.currentThread.getName}\")\n       info.synchronized {\n         // Removals are idempotent in disk store and memory store. At worst, we get a warning.\n         val removedFromMemory = memoryStore.remove(blockId)\n@@ -957,6 +972,7 @@ private[spark] class BlockManager(\n       val entry = iterator.next()\n       val (id, info, time) = (entry.getKey, entry.getValue.value, entry.getValue.timestamp)\n       if (time < cleanupTime && shouldDrop(id)) {\n+        println(s\"Synchronizing on $info dropOldBlocks ${Thread.currentThread.getName}\")\n         info.synchronized {\n           val level = info.level\n           if (level.useMemory) { memoryStore.remove(id) }\ndiff --git a/src/main/scala/spark/examples/src/main/scala/org/apache/spark/examples/STSSparkPi.scala b/src/main/scala/spark/examples/src/main/scala/org/apache/spark/examples/STSSparkPi.scala\nindex 5ec94f3..9618c21 100644\n--- a/src/main/scala/spark/examples/src/main/scala/org/apache/spark/examples/STSSparkPi.scala\n+++ b/src/main/scala/spark/examples/src/main/scala/org/apache/spark/examples/STSSparkPi.scala\n@@ -336,7 +336,7 @@ object STSSparkPi {\n       MyVariables.prematureStopSempahore.release()\n     }\n \n-    val fuzz = false\n+    val fuzz = true\n     if (fuzz) {\n       sched.nonBlockingExplore(prefix, terminationCallback)\n \n@@ -431,7 +431,8 @@ object STSSparkPi {\n         initializationRoutine=Some(runAndCleanup),\n         preTest=Some(preTest), postTest=Some(postTest),\n         clusteringStrategy=ClusteringStrategy.SingletonClusterizer,\n-        paranoid=false)\n+        fungClocksScheduler=TestScheduler.STSSched)\n+        //paranoid=false)\n     }\n   }",
      "status": "On branch spark-2294-blocks\nYour branch is up-to-date with 'origin/spark-2294-blocks'.\nChanges not staged for commit:\n  (use \"git add <file>...\" to update what will be committed)\n  (use \"git checkout -- <file>...\" to discard changes in working directory)\n\n\tmodified:   interposition/src/main/scala/verification/Instrumenter.scala\n\tmodified:   interposition/src/main/scala/verification/RunnerUtils.scala\n\tmodified:   interposition/src/main/scala/verification/minification/domain_specific/FungibleClockClustering.scala\n\tmodified:   interposition/src/main/scala/verification/minification/domain_specific/OneAtATimeClusterizer.scala\n\tmodified:   src/main/scala/spark/core/src/main/scala/org/apache/spark/storage/BlockManager.scala\n\tmodified:   src/main/scala/spark/examples/src/main/scala/org/apache/spark/examples/STSSparkPi.scala\n\nUntracked files:\n  (use \"git add <file>...\" to include in what will be committed)\n\n\tdeadlock.txt\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")"
    }
  },
  "sys": {
    "lsb_release": "",
    "uname": "Darwin yossarian 14.5.0 Darwin Kernel Version 14.5.0: Wed Jul 29 02:26:53 PDT 2015; root:xnu-2782.40.9~1/RELEASE_X86_64 x86_64"
  },
  "timestamp": "2015_09_21_17_53_01",
  "user": "cs"
}
